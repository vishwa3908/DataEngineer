{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics for interview practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "1) Explain about the types of Integration Runtime in ADF and use case of each?\n",
    "2) Explain the use of different triggers in ADF\n",
    "3) What are the optimization techniques you have used in your project. Implementation with use-cases.\n",
    "4) How do you unit test your code in databricks \n",
    "5) Why can't we always use broadcast in Spark \n",
    "6) Where to use Coalesce and where to use Repartition \n",
    "7) Explain how you handle data skew ? Salting in detail.\n",
    "8) How do you handle Merge-conflicts in Git \n",
    "9) How to schedule you pipeline in data bricks \n",
    "10) Difference b/w Parquet table, Delta table and delta live tables\n",
    "11) Explain spark architecture in detail\n",
    "12) What are the benefits of delta table ? Cross-questions on this and data formats.\n",
    "13) Difference b/w CDC and SCDs, when to use which\n",
    "14) Two sum problem \n",
    "15) SQL Questions - Basics questions on window functions(Lead/Lag and rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "1. What are delta live tables and how do they work.\n",
    "2. how can delta tables improve data pipeline , development and managment.\n",
    "3. describe the process of building and deploying a data pipeline using delta live tables.\n",
    "4. what are the benefits of using delta live tables in a data lakehouse.\n",
    "5. what are the key components of a data lakehouse architecture.\n",
    "6. how do you ensure data quality and consistency in a pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
