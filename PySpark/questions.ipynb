{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('questions').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+----------+----+\n",
      "|             PLAYERS|NATIONALITY|         TYPE|PRICE PAID|TEAM|\n",
      "+--------------------+-----------+-------------+----------+----+\n",
      "|Avanish Rao Aravelly|     Indian|Wicket-Keeper|   2000000| CSK|\n",
      "|   Mustafizur Rahman|   Overseas|       Bowler|  20000000| CSK|\n",
      "|      Daryl Mitchell|   Overseas|  All-Rounder| 140000000| CSK|\n",
      "|        Sameer Rizvi|     Indian|       Batter|  84000000| CSK|\n",
      "|     Rachin Ravindra|   Overseas|  All-Rounder|  18000000| CSK|\n",
      "+--------------------+-----------+-------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------+-----------+-----------+----------+\n",
      "|         PLAYER|NATIONALITY|       TYPE|BASE PRICE|\n",
      "+---------------+-----------+-----------+----------+\n",
      "|  Priyansh Arya|     Indian|     Batter|   2000000|\n",
      "|Rohan Kunnummal|     Indian|     Batter|   2000000|\n",
      "|    Manan Vohra|     Indian|     Batter|   2000000|\n",
      "| Raj Angad Bawa|     Indian|All-Rounder|   2000000|\n",
      "|  Sarfaraz Khan|     Indian|All-Rounder|   2000000|\n",
      "+---------------+-----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------+-----------+-------------+\n",
      "|                TEAM|   NATIONALITY|       TYPE|   PRICE PAID|\n",
      "+--------------------+--------------+-----------+-------------+\n",
      "|Kolkata Knight Ri...|Mitchell Starc|     Bowler| 24,75,00,000|\n",
      "| Sunrisers Hyderabad|   Pat Cummins|All-Rounder| 20,50,00,000|\n",
      "| Chennai Super Kings|Daryl Mitchell|All-Rounder| 14,00,00,000|\n",
      "|        Punjab Kings| Harshal Patel|All-Rounder| 11,75,00,000|\n",
      "|Royal Challengers...|Alzarri Joseph|     Bowler| 11,50,00,000|\n",
      "+--------------------+--------------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_players_df = spark.read.format('csv').option('header',True).option('inferSchema',True).load('./csv/IPL_PLAYERS.csv')\n",
    "unsold_payers_df = spark.read.format('csv').option('header',True).option('inferSchema',True).load('./csv/UNSOLD_PLAYERS.csv')\n",
    "top_buys_df = spark.read.format('csv').option('header',True).option('inferSchema',True).load('./csv/TOP_BUYS.csv')\n",
    "all_players_df.show(5)\n",
    "unsold_payers_df.show(5)\n",
    "top_buys_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. Create a dataset from this having origin and destination only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+\n",
      "|cust_id|   Source|Destination|\n",
      "+-------+---------+-----------+\n",
      "|      1|    Delhi|  Mangalore|\n",
      "|      2|   Mumbai|  Gorakhpur|\n",
      "|      3|  Chennai|        Goa|\n",
      "|      4|  Kolkata|  Ahmedabad|\n",
      "|      5|Hyderabad|Bhubaneswar|\n",
      "|      6|Bengaluru|     Jaipur|\n",
      "|      7|  Lucknow|    Kolkata|\n",
      "|      8|   Indore|     Bhopal|\n",
      "+-------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_df = spark.read.format('csv').option('header',True).option('inferSchema',True).load('./csv/flight_data.csv')\n",
    "\n",
    "# Method 1\n",
    "# flight_df.show()\n",
    "flight_df_1 = flight_df.withColumn('row_num',row_number().over(Window.partitionBy(col('cust_id')).orderBy(col('cust_id'))))\n",
    "# flight_df.show()\n",
    "flight_df_1 = flight_df_1.groupBy(col('cust_id')).agg(first(col('origin')).alias('Source'),last(col('destination')).alias('Destination'))\n",
    "flight_df_1.show()\n",
    "\n",
    "# Method 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
